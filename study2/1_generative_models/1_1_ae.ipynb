{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1 AutoEncoder\n",
    "\n",
    "<img src=\"./img/ae.png\" alt=\"autoencoder\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 임포트\n",
    "\n",
    "- os (디렉토리 생성)\n",
    "- tensorflow (학습)\n",
    "- numpy (랜덤데이터 플로팅)\n",
    "- matplotlib.pyplot (플로팅)\n",
    "- matplotlib.gridspec (플로팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Directory 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"../generated_output/AE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 변수 설정\n",
    "\n",
    "- learning rate : gradient descent시 적용할 학습률\n",
    "- training steps : training 종료조건\n",
    "- batch size : 1 step에 feed forward할 배치 크기\n",
    "\n",
    "- 1 step에 batch size만큼의 데이터를 feed forward하기 때문에, step * batch size = feed forward된 데이터 샘플수\n",
    "- 1 epoch은 총 sample수를 사용하여 학습한 것을 의미하므로, feed forward된 sample수 / 데이터 sample수 = epoch수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_STEPS = 60000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 변수 설정\n",
    "\n",
    "- image dimension : 이미지 차원, MNIST가 28x28이므로 총 784차원의 벡터\n",
    "- latent dimension : 임베딩할 차원\n",
    "- encoder hidden dimension : 인코더 파트의 은닉층 차원\n",
    "- decoder hidden dimension : 디코더 파트의 은닉층 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 784\n",
    "LATENT_DIM = 10\n",
    "ENDOCER_HIDDEN_DIM = 256\n",
    "DECODER_HIDDEN_DIM = 256\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 함수 정의\n",
    "\n",
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 10) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 10]\n",
    "\n",
    "#### Initialization 구현\n",
    "\n",
    "shape = [784, 256]일 때, 이에 대한 weight initialization 구현법  \n",
    "(실용 코드에서는 tensorflow. initializers에 함수로 구현되어, 호출만 하면 됨)\n",
    "\n",
    "1. Lecun initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(1. / (shape[0]))\n",
    "\n",
    "2. Glorot initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(2. / (shape[0] + shape[1])))\n",
    "\n",
    "3. He initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(2. / shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(feature):\n",
    "    \n",
    "    with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        net = feature\n",
    "            \n",
    "        net = tf.layers.dense(\n",
    "            net, ENDOCER_HIDDEN_DIM, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # tf.layers.dense(input, output dim)\n",
    "        # hidden layer의 activation function은 relu를 씀 (gradient vanishing 방지)\n",
    "        # initializer은 he initialization을 씀 (relu에 최적화, stddev = sqrt(2/fan_in))\n",
    "                    \n",
    "        net = tf.layers.dense(\n",
    "            net, LATENT_DIM, \n",
    "            activation=tf.nn.sigmoid, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # output layer\n",
    "        # output layer의 activation function은 sigmoid를 씀 (0 ~ 1로 mapping)\n",
    "        \n",
    "        return net\n",
    "        # output layer을 거친 tensor을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 함수 정의\n",
    "\n",
    "[batch_size, 10]\n",
    "\n",
    "$\\rightarrow$ Dense(10, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_model(feature):\n",
    "    \n",
    "    with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        net = feature\n",
    "            \n",
    "        net = tf.layers.dense(\n",
    "            net, DECODER_HIDDEN_DIM, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # tf.layers.dense(input, output dim)\n",
    "        # 반복문을 통해 hidden dimension 리스트 형태로 hidden layer 구성\n",
    "        # hidden layer의 activation function은 relu를 씀 (gradient vanishing 방지)\n",
    "        # initializer은 he initialization을 씀 (relu에 최적화, stddev = sqrt(2/fan_in))\n",
    "            \n",
    "        net = tf.layers.dense(\n",
    "            net, IMAGE_DIM, \n",
    "            activation=tf.nn.sigmoid, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # output layer\n",
    "        # output layer의 activation function은 sigmoid를 씀 (0~1로 mapping)\n",
    "        \n",
    "        return net\n",
    "        # output layer을 거친 tensor을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function 정의\n",
    "\n",
    "feature\n",
    "\n",
    "$\\rightarrow$ Dataset 생성 $\\rightarrow$ 데이터 사이즈로 랜덤 셔플링 $\\rightarrow$ 데이터 모두 소모시 처음부터 반복\n",
    "\n",
    "$\\rightarrow$ batch 생성 $\\rightarrow$ batch 한 개씩 소모하는 iterator $\\rightarrow$ iterator 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "        # 인풋값으로부터 Dataset객체 생성\n",
    "        batch_dataset = dataset.shuffle(features.shape[0]).repeat().batch(batch_size)\n",
    "        # Dataset 셔플링, 반복, 배치화\n",
    "        return batch_dataset.make_one_shot_iterator().get_next()\n",
    "        # 단일 배치 반복자 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder 학습 함수 정의\n",
    "\n",
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 10) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 10]\n",
    "\n",
    "$\\rightarrow$ Dense(10, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features):\n",
    "    \n",
    "    if not os.path.exists(CKPT_DIR):\n",
    "        os.makedirs(CKPT_DIR)\n",
    "    # logging directory 생성\n",
    "        \n",
    "    with graph.as_default():\n",
    "        \n",
    "        features = train_input_fn(features)\n",
    "        # feature 받아서 batch로 넘겨주는 그래프 작성\n",
    "        \n",
    "        latents = encoder_model(features)\n",
    "        # batch를 encoder에 적용하여 latent를 추출하는 그래프 작성\n",
    "        \n",
    "        outputs = decoder_model(latents)\n",
    "        # latent를 decoder에 적용하여 복원하는 그래프 작성\n",
    "        \n",
    "        loss = tf.losses.mean_squared_error(features, outputs)\n",
    "        # loss는 input feature와 MSE로 정의\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "        # backpropagation operation 정의\n",
    "        # optimizer은 ADAM 적용, 설정한 learning rate 적용\n",
    "                \n",
    "        saver = tf.train.Saver()                                 \n",
    "        # checkpoint 저장할 Saver객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "        # Session객체 생성, 컨텍스트 매니저로 자원 관리\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # weight 초기화\n",
    "\n",
    "            for step in range(TRAINING_STEPS):\n",
    "                \n",
    "                step += 1\n",
    "                                \n",
    "                loss_now, _ = sess.run([loss, optimizer])\n",
    "                # feedforward, backpropagation 실행\n",
    "                # Plotting할 embedding assigning operation도 같이 실행\n",
    "                # 한 번의 run을 통해 실행해야 batch iterator가 한 번만 실행됨에 유의\n",
    "                                \n",
    "                if (step == TRAINING_STEPS):                \n",
    "                    saver.save(sess, CKPT_DIR + '/ae.ckpt')\n",
    "                    # 학습된 weights에 대한 checkpoint 저장\n",
    "                    \n",
    "                if (step % 1000 == 0):\n",
    "                    print('steps: {}/{}, loss: {:.4f}'.format(step, TRAINING_STEPS, loss_now))\n",
    "                    # 학습과정 로깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 로드 및 전처리\n",
    "- MNIST 데이터 로드\n",
    "- normalize\n",
    "- flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# MNIST 데이터 로드 (keras.datesets 모듈 이용)\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "# MNIST 데이터 normalize (0~1로 mapping)\n",
    "\n",
    "x_train = x_train.reshape([-1, IMAGE_DIM]).astype(np.float32)\n",
    "x_test = x_test.reshape([-1, IMAGE_DIM]).astype(np.float32)\n",
    "# MNIST 데이터 vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_25_image_plot(features):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "        batch_dataset = dataset.batch(25)\n",
    "        features = batch_dataset.make_one_shot_iterator().get_next()\n",
    "        # plotting batch 생성\n",
    "        \n",
    "        latents = encoder_model(features)\n",
    "        # vector을 encoder에 적용하여 latent 추출\n",
    "        \n",
    "        recon = decoder_model(latents)\n",
    "        # latent를 decoder에 적용하여 복원\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        gs = gridspec.GridSpec(5, 5)\n",
    "        gs.update(wspace=0.05)\n",
    "        # 플로팅 사이즈, 배열, 간격 정의\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        # weight restoring 진행할 Saver 객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            saver.restore(sess, tf.train.latest_checkpoint(CKPT_DIR))\n",
    "            # checkpoint로부터 weight 복원\n",
    "            \n",
    "            recon_image = sess.run(recon)\n",
    "            # reconstruction operation 진행\n",
    "            \n",
    "            recon_image = recon_image.reshape([-1, 28, 28])\n",
    "            # tensorization\n",
    "            \n",
    "            for i in range(25):\n",
    "                plt.subplot(gs[i])\n",
    "                plt.axis('off')\n",
    "                plt.imshow(recon_image[i], cmap = 'gray')\n",
    "            # reconstructed image plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def origin_25_image_plot(features):\n",
    "    features = features.reshape([-1, 28, 28])\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(5, 5)\n",
    "    gs.update(wspace=0.05)\n",
    "    for i in range(25):\n",
    "        plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(features[i], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_25_image_plot(x_test[:25])\n",
    "origin_25_image_plot(x_test[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_25_image_plot(seed=None):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        random_noise = np.random.normal(size=[25, LATENT_DIM]).astype(np.float32)\n",
    "        # latent 형태의 random noise 생성\n",
    "        \n",
    "        random_noise_input = train_input_fn(random_noise, batch_size=25)\n",
    "        # random noise tensor 생성\n",
    "        \n",
    "        random_gen = decoder_model(random_noise_input)\n",
    "        # random noise를 decoder에 적용, MNIST image 차원으로 임베딩\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        gs = gridspec.GridSpec(5, 5)\n",
    "        gs.update(wspace=0.05)\n",
    "        # 플로팅 사이즈, 배열, 간격 정의\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        # weight restoring 진행할 Saver 객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            saver.restore(sess, tf.train.latest_checkpoint(CKPT_DIR))\n",
    "            # checkpoint로부터 weight 복원\n",
    "            \n",
    "            random_image = sess.run(random_gen)\n",
    "            # random generation operation 진행\n",
    "            \n",
    "            random_image = random_image.reshape([-1, 28, 28])\n",
    "            # tensorization\n",
    "            \n",
    "            for i in range(25):\n",
    "                plt.subplot(gs[i])\n",
    "                plt.axis('off')\n",
    "                plt.imshow(random_image[i], cmap = 'gray')\n",
    "            # plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_25_image_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
