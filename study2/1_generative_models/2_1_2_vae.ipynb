{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2 Variational AutoEncoder\n",
    "\n",
    "<img src=\"./img/vae.png\" alt=\"variationalautoencoder\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 임포트\n",
    "\n",
    "- os (디렉토리 생성)\n",
    "- tensorflow (학습)\n",
    "- numpy (랜덤데이터 플로팅)\n",
    "- matplotlib.pyplot (플로팅)\n",
    "- matplotlib.gridspec (플로팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Directory 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"../generated_output/VAE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 변수 설정\n",
    "\n",
    "- learning rate : gradient descent시 적용할 학습률\n",
    "- training steps : training 종료조건\n",
    "- batch size : 1 step에 feed forward할 배치 크기\n",
    "\n",
    "- 1 step에 batch size만큼의 데이터를 feed forward하기 때문에, step * batch size = feed forward된 데이터 샘플수\n",
    "- 1 epoch은 총 sample수를 사용하여 학습한 것을 의미하므로, feed forward된 sample수 / 데이터 sample수 = epoch수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_STEPS = 60000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 변수 설정\n",
    "\n",
    "- image dimension : 이미지 차원, Fashion-MNIST가 28x28이므로 총 784차원의 벡터\n",
    "- latent dimension : 임베딩할 차원\n",
    "- encoder hidden dimension : 인코더 파트의 은닉층 차원\n",
    "- decoder hidden dimension : 디코더 파트의 은닉층 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 784\n",
    "LATENT_DIM = 10\n",
    "ENCODER_HIDDEN_DIM = 256\n",
    "DECODER_HIDDEN_DIM = 256\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 함수 정의\n",
    "\n",
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ 2 x Dense(256, 10) $\\rightarrow$ 2 x [batch_size, 10]\n",
    "\n",
    "#### Initialization 구현\n",
    "\n",
    "shape = [784, 256]일 때, 이에 대한 weight initialization 구현법  \n",
    "(실용 코드에서는 tensorflow. initializers에 함수로 구현되어, 호출만 하면 됨)\n",
    "\n",
    "1. Lecun initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(1. / (shape[0]))\n",
    "\n",
    "2. Glorot initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(2. / (shape[0] + shape[1])))\n",
    "\n",
    "3. He initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(2. / shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(features):\n",
    "    \n",
    "    with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        net = features\n",
    "        \n",
    "        net = tf.layers.dense(\n",
    "            net, ENCODER_HIDDEN_DIM, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # tf.layers.dense(input, output dim)\n",
    "        # 반복문을 통해 hidden dimension 리스트 형태로 hidden layer 구성\n",
    "        # hidden layer의 activation function은 relu를 씀 (gradient vanishing 방지)\n",
    "        # initializer은 he initialization을 씀 (relu에 최적화, stddev = sqrt(2/fan_in))            \n",
    "            \n",
    "        latent_mean = tf.layers.dense(\n",
    "            net, LATENT_DIM, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # latent의 mean으로의 embedding\n",
    "        \n",
    "        latent_log_var = tf.layers.dense(\n",
    "            net, LATENT_DIM, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # latent의 stddev으로의 embedding (계산 편의상 stddev대신 log variance를 이용)\n",
    "        \n",
    "        return latent_mean, latent_log_var\n",
    "        # latent의 mean과 stddev(log variance) embedding tensor 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling 함수 정의\n",
    "\n",
    "- encoding하여 얻은 mean과 stddev(log variance)를 이용하여 random sampling하는 함수 정의 \n",
    "\n",
    "2 x [batch_size, 10] $\\rightarrow$ [batch_size, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_model(latent_mean, latent_log_var):\n",
    "    \n",
    "    with tf.variable_scope('sampler', reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        snd_sample = tf.random_normal(\n",
    "            tf.shape(latent_log_var), dtype=tf.float32, \n",
    "            mean=0., stddev=1.0)\n",
    "        # latent 차원의 표준정규분포 샘플링\n",
    "        \n",
    "        latent_std = tf.exp(latent_log_var / 2)\n",
    "        # log variance를 통하여 stddev계산\n",
    "        \n",
    "        latent = latent_mean + latent_std * snd_sample\n",
    "        # 표준정규분포를 latent mean, latent stddev에 해당하는 샘플로 변환\n",
    "        # tf.random_normal이 mean, stddev로서 단일값 혹은 0-D tensor을 받기 때문에 이런 식으로 샘플링\n",
    "        \n",
    "        return latent\n",
    "        # 샘플링 된 gaussian distribution형태의 latent 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 함수 정의\n",
    "\n",
    "[batch_size, 10]\n",
    "\n",
    "$\\rightarrow$ Dense(128, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_model(features):\n",
    "    \n",
    "    with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        net = features\n",
    "        \n",
    "        net = tf.layers.dense(\n",
    "            net, DECODER_HIDDEN_DIM, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # tf.layers.dense(input, output dim)\n",
    "        # 반복문을 통해 hidden dimension 리스트 형태로 hidden layer 구성\n",
    "        # hidden layer의 activation function은 relu를 씀 (gradient vanishing 방지)\n",
    "        # initializer은 he initialization을 씀 (relu에 최적화, stddev = sqrt(2/fan_in))\n",
    "            \n",
    "        recon = tf.layers.dense(\n",
    "            net, IMAGE_DIM, \n",
    "            activation=tf.nn.sigmoid, \n",
    "            kernel_initializer=tf.initializers.he_normal())\n",
    "        # output layer\n",
    "        # output layer의 activation function은 sigmoid를 씀 (0~1로 mapping)\n",
    "        \n",
    "        return recon\n",
    "        # output layer을 거친 tensor을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function 정의\n",
    "\n",
    "feature\n",
    "\n",
    "$\\rightarrow$ Dataset 생성 $\\rightarrow$ 데이터 사이즈로 랜덤 셔플링 $\\rightarrow$ 데이터 모두 소모시 처음부터 반복\n",
    "\n",
    "$\\rightarrow$ batch 생성 $\\rightarrow$ batch 한 개씩 소모하는 iterator $\\rightarrow$ iterator 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "        # 인풋값으로부터 Dataset객체 생성\n",
    "        batch_dataset = dataset.shuffle(features.shape[0]).repeat().batch(batch_size)\n",
    "        # Dataset 셔플링, 반복, 배치화\n",
    "        return batch_dataset.make_one_shot_iterator().get_next()\n",
    "        # 단일 배치 반복자 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/vae_recloss.png\" alt=\"vae_recloss\" width=\"400\" align=\"top\"/>\n",
    "<img src=\"./img/vae_regloss.png\" alt=\"vae_regloss\" width=\"450\" align=\"top\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Loss\n",
    "\n",
    "- 직접 mean을 0으로, stddev를 1로 보내는 loss를 설계할 경우와의 차이\n",
    "    - MSE혹은 cross-entropy를 이용하여 latent 모수를 직접 특정 값으로 보낼 경우\n",
    "        - 레이블에 관계 없이 모든 mean은 0으로 mapping되고, stddev은 1로 mapping됨\n",
    "        - sampling bias를 이용한 random generation 적용 불가\n",
    "    - Distribution의 KL-Divergence를 이용할 경우\n",
    "        - 각각의 mean, stddev은 다양한 값들을 가짐 (물론, 중심점으로부터 멀지는 않음)\n",
    "        - 단, 다양한 mean과 stddev의 데이터가 혼합된 batch embedding은 표준정규분포의 형태가 됨\n",
    "        - 표준정규분포 내부에 데이터 특성에 따라 biased된 정규분포가 존재하는 형태\n",
    "        \n",
    "- 표준정규분포에서의 샘플링시 sampling bias 발생\n",
    "    - 표본평균과 표본표준편차에 따라 특정 특징을 지닌 이미지로 mapping\n",
    "    - 이를 통하여 학습 데이터셋에 포함되어있던 다양한 이미지 생성 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(features, outputs, latent_mean, latent_log_var):\n",
    "    \n",
    "    rec_loss = tf.reduce_sum(\n",
    "        tf.keras.backend.binary_crossentropy(features, outputs), 1)\n",
    "    # reconstruction loss (cross-entropy btw input image and output image)\n",
    "    # reconstructed image를 원본과 유사하게 하는 역할을 하는 loss\n",
    "\n",
    "    reg_loss = -0.5 * tf.reduce_sum(\n",
    "        1 + latent_log_var \n",
    "        - tf.square(latent_mean) \n",
    "        - tf.exp(latent_log_var), 1)\n",
    "    # regularization loss (KL-Divergence btw latent and N(0,1))\n",
    "    # latent를 표준정규분포에 가깝게 가져가는 역할을 하는 loss\n",
    "    \n",
    "    return tf.reduce_mean(rec_loss + reg_loss)\n",
    "    # reconstruction loss + regularization loss 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational AutoEncoder 학습 함수 정의\n",
    "\n",
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ 2 x Dense(256, 10) $\\rightarrow$ 2 x [batch_size, 10]\n",
    "\n",
    "$\\rightarrow$ Gaussian Distribution Sampling $\\rightarrow$ [batch_size, 10]\n",
    "\n",
    "$\\rightarrow$ Dense(128, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features):\n",
    "    if not os.path.exists(os.path.dirname(CKPT_DIR)):\n",
    "        os.makedirs(os.path.dirname(CKPT_DIR))\n",
    "    # logging directory 생성\n",
    "\n",
    "    with graph.as_default():\n",
    "        \n",
    "        features = train_input_fn(features)\n",
    "        # feature 받아서 batch로 넘겨주는 그래프 작성\n",
    "        latent_mean, latent_log_var = encoder_model(features)\n",
    "        # batch를 encoder에 적용하여 latent의 mean과 stddev(log variance)를 추출하는 그래프 작성\n",
    "        sample = sampler_model(latent_mean, latent_log_var)\n",
    "        # mean과 stddev(log variance)이용하여 샘플링하여 latent를 생성하는 그래프 작성\n",
    "        outputs = decoder_model(sample)\n",
    "        # latent를 decoder에 적용하여 복원하는 그래프 작성\n",
    "        loss = vae_loss(features, outputs, latent_mean, latent_log_var)\n",
    "        # loss는 reconstruction loss + regularization loss\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "        # backpropagation operation 정의\n",
    "        # optimizer은 ADAM 적용, 설정한 learning rate 적용\n",
    "        saver = tf.train.Saver()\n",
    "        # checkpoint 저장할 Saver객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "        # Session객체 생성, 컨텍스트 매니저로 자원 관리\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # weight 초기화\n",
    "\n",
    "            for step in range(TRAINING_STEPS):\n",
    "                step += 1             \n",
    "                loss_now, _ = sess.run([loss, optimizer])\n",
    "                # feedforward, backpropagation 실행\n",
    "                # Plotting할 embedding assigning operation도 같이 실행\n",
    "                # 한 번의 run을 통해 실행해야 batch iterator가 한 번만 실행됨에 유의\n",
    "                if (step == TRAINING_STEPS):    \n",
    "                    saver.save(sess, CKPT_DIR + '/vae.ckpt')\n",
    "                    # 학습된 weights에 대한 checkpoint 저장\n",
    "                if (step % 1000 == 0):\n",
    "                    print('steps: {}/{}, loss: {:.4f}'.format(step, TRAINING_STEPS, loss_now))\n",
    "                    # 학습과정 로깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion-MNIST 데이터 로드 및 전처리\n",
    "- Fashion-MNIST 데이터 로드\n",
    "- normalize\n",
    "- flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# Fashion-MNIST 데이터 로드 (keras.datesets 모듈 이용)\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "# Fashion-MNIST 데이터 normalize (0~1로 mapping)\n",
    "\n",
    "x_train = x_train.reshape([-1, IMAGE_DIM]).astype(np.float32)\n",
    "x_test = x_test.reshape([-1, IMAGE_DIM]).astype(np.float32)\n",
    "# Fashion-MNIST 데이터 vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational AutoEncoder 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_25_image_plot(features):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "        batch_dataset = dataset.batch(25)\n",
    "        features = batch_dataset.make_one_shot_iterator().get_next()\n",
    "        # plotting batch 생성\n",
    "        \n",
    "        latent_mean, latent_log_var = encoder_model(features)\n",
    "        # vector을 encoder에 적용하여 latent 추출\n",
    "        latents = sampler_model(latent_mean, latent_log_var)\n",
    "        recon = decoder_model(latents)\n",
    "        # latent를 decoder에 적용하여 복원\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        gs = gridspec.GridSpec(5, 5)\n",
    "        gs.update(wspace=0.05)\n",
    "        # 플로팅 사이즈, 배열, 간격 정의\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        # weight restoring 진행할 Saver 객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            saver.restore(sess, tf.train.latest_checkpoint(CKPT_DIR))\n",
    "            # checkpoint로부터 weight 복원\n",
    "            \n",
    "            recon_image = sess.run(recon)\n",
    "            # reconstruction operation 진행\n",
    "            \n",
    "            recon_image = recon_image.reshape([-1, 28, 28])\n",
    "            # tensorization\n",
    "            \n",
    "            for i in range(25):\n",
    "                plt.subplot(gs[i])\n",
    "                plt.axis('off')\n",
    "                plt.imshow(recon_image[i], cmap = 'gray')\n",
    "            # reconstructed image plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def origin_25_image_plot(features):\n",
    "    features = features.reshape([-1, 28, 28])\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(5, 5)\n",
    "    gs.update(wspace=0.05)\n",
    "    for i in range(25):\n",
    "        plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(features[i], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_25_image_plot(x_test[:25])\n",
    "origin_25_image_plot(x_test[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_25_image_plot(seed=None):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        random_noise = np.random.normal(size=[25, LATENT_DIM]).astype(np.float32)\n",
    "        # latent 형태의 random noise 생성\n",
    "        \n",
    "        random_noise_input = train_input_fn(random_noise, batch_size=25)\n",
    "        # random noise tensor 생성\n",
    "        \n",
    "        random_gen = decoder_model(random_noise_input)\n",
    "        # random noise를 decoder에 적용, Fashion-MNIST image 차원으로 임베딩\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        gs = gridspec.GridSpec(5, 5)\n",
    "        gs.update(wspace=0.05)\n",
    "        # 플로팅 사이즈, 배열, 간격 정의\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        # weight restoring 진행할 Saver 객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            saver.restore(sess, tf.train.latest_checkpoint(CKPT_DIR))\n",
    "            # checkpoint로부터 weight 복원\n",
    "            \n",
    "            random_image = sess.run(random_gen)\n",
    "            # random generation operation 진행\n",
    "            \n",
    "            random_image = random_image.reshape([-1, 28, 28])\n",
    "            # tensorization\n",
    "            \n",
    "            for i in range(25):\n",
    "                plt.subplot(gs[i])\n",
    "                plt.axis('off')\n",
    "                plt.imshow(random_image[i], cmap = 'gray')\n",
    "            # plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_25_image_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
