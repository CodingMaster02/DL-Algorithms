{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN) 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/gan.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 import\n",
    "* tensorflow (신경망 구성, 변수 설정, 역전파, gradient descent etc)\n",
    "* numpy (텐서 연산)\n",
    "* matplotlib (결과 그래프 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터세트 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라메터 설정\n",
    "* hyper parameter는 사용자가 정의하는 변수들 \n",
    "* learnable parameter는 학습을 통해 업데이트되는 변수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters (hyper parameters)\n",
    "num_steps = 70000\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Network Parameters (learnable parameters)\n",
    "image_dim = 784 # 28*28 pixels\n",
    "gen_hidden_dim = 256\n",
    "dis_hidden_dim = 256\n",
    "noise_dim = 100 # Noise data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initialization by Xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 러너블 파라메터 설정 (learnable parameter = network parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "\n",
    "weights = {\n",
    "    'gen_hidden': tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n",
    "    'dis_hidden': tf.Variable(glorot_init([image_dim, dis_hidden_dim])),\n",
    "    'dis_out': tf.Variable(glorot_init([dis_hidden_dim, 1])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'gen_hidden': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(tf.zeros([image_dim])),\n",
    "    'dis_hidden': tf.Variable(tf.zeros([dis_hidden_dim])),\n",
    "    'dis_out': tf.Variable(tf.zeros([1])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator & Discriminator 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/gan_generator.png\" width=\"50%\">\n",
    "<img src=\"./img/gan_discriminator.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['gen_hidden'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['gen_hidden'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
    "    out_layer = tf.add(out_layer, biases['gen_out'])    \n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "def discriminator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['dis_hidden'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['dis_hidden'])    \n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['dis_out'])\n",
    "    out_layer = tf.add(out_layer, biases['dis_out'])    \n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function 정의 (Loss for Generator & Loss for Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Network Inputs\n",
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
    "dis_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='dis_input')\n",
    "\n",
    "# Build Generator Network\n",
    "gen_sample = generator(gen_input)\n",
    "\n",
    "# Build two Discriminator Networks (one from noise input, one from generated samples)\n",
    "dis_real = discriminator(dis_input)\n",
    "dis_fake = discriminator(gen_sample)\n",
    "\n",
    "# Build Loss\n",
    "gen_loss = -tf.reduce_mean(tf.log(dis_fake))\n",
    "dis_loss = -tf.reduce_mean(tf.log(dis_real) + tf.log(1. - dis_fake))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent & Back Propagation by optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_dis = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "\n",
    "# Generator Network Variables\n",
    "gen_vars = [weights['gen_hidden'], weights['gen_out'],\n",
    "            biases['gen_hidden'], biases['gen_out']]\n",
    "\n",
    "# Discriminator Network Variables\n",
    "dis_vars = [weights['dis_hidden'], weights['dis_out'],\n",
    "            biases['dis_hidden'], biases['dis_out']]\n",
    "\n",
    "# Create training operations\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_dis = optimizer_dis.minimize(dis_loss, var_list=dis_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "\n",
    "    # Train\n",
    "    feed_dict = {dis_input: batch_x, gen_input: z}\n",
    "    _, _, gl, dl = sess.run([train_gen, train_dis, gen_loss, dis_loss],\n",
    "                            feed_dict=feed_dict)\n",
    "    if i % 2000 == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 및 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Generate images from noise, using the generator network.\n",
    "\n",
    "n = 5\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "\n",
    "for i in range(n):\n",
    "    # Noise input.\n",
    "    z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "    \n",
    "    # Generate image from noise.\n",
    "    g = sess.run(gen_sample, feed_dict={gen_input: z})\n",
    "    \n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    \n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
