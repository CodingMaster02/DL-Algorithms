{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-3 GAN\n",
    "\n",
    "<img src=\"./img/gan.png\" alt=\"gan\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 임포트\n",
    "- os (디렉토리 생성)\n",
    "- tensorflow (학습)\n",
    "- numpy (랜덤데이터 플로팅)\n",
    "- matplotlib.pyplot (플로팅)\n",
    "- matplotlib.gridspec (플로팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Directory 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = '../generated_output/GAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 변수 설정\n",
    "- learning rate : gradient descent시 적용할 학습률\n",
    "- training steps : training 종료조건\n",
    "- batch size : 1 step에 feed forward할 배치 크기\n",
    "\n",
    "- 1 step에 batch size만큼의 데이터를 feed forward하기 때문에, step * batch size = feed forward된 데이터 샘플수\n",
    "- 1 epoch은 총 sample수를 사용하여 학습한 것을 의미하므로, feed forward된 sample수 / 데이터 sample수 = epoch수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(10)\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_STEPS = 60000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 변수 설정\n",
    "- image dimension : 이미지 차원, Fashion-MNIST가 28x28이므로 총 784차원의 벡터\n",
    "- noise dimension : 랜덤 샘플링할 차원\n",
    "- generator hidden dimension : generator 파트의 은닉층 차원\n",
    "- discriminator hidden dimension : discriminator 파트의 은닉층 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 784\n",
    "NOISE_DIM = 100\n",
    "GEN_HIDDEN_DIM = 256\n",
    "DISC_HIDDEN_DIM = 256\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator 함수 정의\n",
    "\n",
    "[batch_size, 784]\n",
    "\n",
    "$\\rightarrow$ Dense(784, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 1) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 1]\n",
    "\n",
    "#### Initialization 구현\n",
    "\n",
    "shape = [784, 256]일 때, 이에 대한 weight initialization 구현법  \n",
    "(실용 코드에서는 tensorflow. initializers에 함수로 구현되어, 호출만 하면 됨)\n",
    "\n",
    "1. Lecun initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(1. / (shape[0]))\n",
    "\n",
    "2. Glorot initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(2. / (shape[0] + shape[1])))\n",
    "\n",
    "3. He initialization\n",
    "\n",
    "> tf.random_normal(shape=[shape], stddev=tf.sqrt(2. / shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_model(features):\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
    "    # variable scope 이용하여 선별적 weight update 진행\n",
    "\n",
    "        net = features\n",
    "        \n",
    "        net = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                         input_shape=[28, 28, 1], name='d_c_1')(net)\n",
    "        net = tf.keras.layers.LeakyReLU()(net)\n",
    "        net = tf.keras.layers.Dropout(0.3)(net)\n",
    "        net = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', name='d_c_2')(net)\n",
    "        net = tf.keras.layers.LeakyReLU()(net)\n",
    "        net = tf.keras.layers.Dropout(0.3)(net)\n",
    "        net = tf.keras.layers.Flatten()(net)\n",
    "        net = tf.keras.layers.Dense(1, name='d_d_3')(net)\n",
    "    \n",
    "        return net\n",
    "        # output layer을 거친 tensor을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 함수 정의\n",
    "\n",
    "[batch_size, 100]\n",
    "\n",
    "$\\rightarrow$ Dense(100, 256) $\\rightarrow$ relu $\\rightarrow$ [batch_size, 256]\n",
    "\n",
    "$\\rightarrow$ Dense(256, 784) $\\rightarrow$ sigmoid $\\rightarrow$ [batch_size, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(features):\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
    "    # variable scope 이용하여 선별적 weight update 진행\n",
    "        \n",
    "        net = features\n",
    "        \n",
    "        net = tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,), name='g_d_1')(net)\n",
    "        net = tf.keras.layers.BatchNormalization(name='g_b_1')(net)\n",
    "        net = tf.keras.layers.LeakyReLU()(net)\n",
    "        net = tf.keras.layers.Reshape((7, 7, 256))(net)\n",
    " \n",
    "        net = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False, name='g_c_2')(net)\n",
    "        net = tf.keras.layers.BatchNormalization(name='g_b_2')(net)\n",
    "        net = tf.keras.layers.LeakyReLU()(net)\n",
    "\n",
    "        net = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, name='g_c_3')(net)\n",
    "        net = tf.keras.layers.BatchNormalization(name='g_b_3')(net)\n",
    "        net = tf.keras.layers.LeakyReLU()(net)\n",
    "\n",
    "        net = tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh', name='g_c_o')(net)\n",
    "        \n",
    "        return net\n",
    "        # output layer을 거친 tensor을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function 정의\n",
    "\n",
    "feature\n",
    "\n",
    "$\\rightarrow$ Dataset 생성 $\\rightarrow$ 데이터 사이즈로 랜덤 셔플링 $\\rightarrow$ 데이터 모두 소모시 처음부터 반복\n",
    "\n",
    "$\\rightarrow$ batch 생성 $\\rightarrow$ batch 한 개씩 소모하는 iterator $\\rightarrow$ iterator 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "        # 인풋값으로부터 Dataset객체 생성\n",
    "        batch_dataset = dataset.shuffle(features.shape[0]).repeat().batch(batch_size)\n",
    "        # Dataset 셔플링, 반복, 배치화\n",
    "        batch = batch_dataset.make_one_shot_iterator().get_next()\n",
    "        # 단일 배치 반복자 리턴\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/gan_loss.png\" alt=\"ganloss\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features):\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(CKPT_DIR)):\n",
    "        os.makedirs(os.path.dirname(CKPT_DIR))\n",
    "    # logging directory 생성\n",
    "        \n",
    "    with graph.as_default():\n",
    "        \n",
    "        features = train_input_fn(features)\n",
    "        # feature 받아서 batch로 넘겨주는 그래프 작성\n",
    "\n",
    "        real_image = features\n",
    "        # real image는 입력받는 이미지 tensor\n",
    "        \n",
    "        fake_noise = tf.random.normal(\n",
    "            shape=[BATCH_SIZE, NOISE_DIM], \n",
    "            dtype=tf.float32)\n",
    "        # fake noise는 -1~1의 uniform distribution으로 sampling한 tensor\n",
    "        \n",
    "        fake_image = gen_model(fake_noise)\n",
    "        # fake image는 fake nose를 generator에 적용하여 얻은 이미지\n",
    "        \n",
    "        disc_real = disc_model(real_image)\n",
    "        # discriminator에 real image가 들어온 경우의 tensor\n",
    "        \n",
    "        disc_fake = disc_model(fake_image)\n",
    "        # discriminator에 fake image가 들어온 경우의 tensor\n",
    "        \n",
    "        disc_real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_real), disc_real)\n",
    "        disc_fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(disc_fake), disc_fake)\n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "        # discriminator loss (상기 그림 중 좌측)\n",
    "        # discriminator 끝단에 sigmoid가 붙어있기에 0~1로 mapping됨\n",
    "        # real image는 1로 판정하고자 함 (-log(1) = 0, -log(0) = inf)\n",
    "        # fake image는 0으로 판정하고자 함 (-log(1-1) = inf, -log(1-0) = 0)\n",
    "        \n",
    "        gen_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_fake), disc_fake)\n",
    "        # generator loss (상기 그림 중 우측)\n",
    "        # gen_loss = tf.reduce_mean(tf.log(1. - disc_fake)) 의 대체 로스 (gradient vanishing 방지)\n",
    "        # real값에 대한 discriminator loss항을 대신 이용\n",
    "        # fake image를 discriminator가 1로 판정하도록 속이고자 함\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "        \n",
    "            opt_disc = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "            # discriminator의 optimizer 정의\n",
    "            # optimizer은 ADAM 적용, 설정한 learning rate 적용\n",
    "\n",
    "            opt_gen = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "            # generator의 optimizer 정의\n",
    "            # optimizer은 ADAM 적용, 설정한 learning rate 적용\n",
    "\n",
    "            grads_disc = tf.gradients(\n",
    "                disc_loss,\n",
    "                tf.get_collection(\n",
    "                    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"discriminator\"))\n",
    "            # discriminator의 gradient 계산\n",
    "            # discriminator variable scope의 weight에 대해서만 discriminator loss적용\n",
    "\n",
    "            grads_gen = tf.gradients(\n",
    "                gen_loss, \n",
    "                tf.get_collection(\n",
    "                    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"generator\"))\n",
    "            # generator의 gradient 계산\n",
    "            # generator variable scope의 weight에 대해서만 generator loss적용\n",
    "\n",
    "            grads_disc = list(zip(grads_disc, tf.get_collection(\n",
    "                    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"discriminator\")))\n",
    "                    # discriminator의 gradient를 각 웨이트값과 매칭(apply gradient하기 위함)\n",
    "            grads_gen = list(zip(grads_gen, tf.get_collection(\n",
    "                    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"generator\")))\n",
    "                    # generator의 gradient를 각 웨이트값과 매칭(apply gradient하기 위함)\n",
    "\n",
    "            op_disc = opt_disc.apply_gradients(grads_disc)\n",
    "            # discriminator에 대하여 gradient적용하여 최적화\n",
    "            op_gen = opt_gen.apply_gradients(grads_gen)\n",
    "            # generator에 대하여 gradient 적용하여 최적화\n",
    "\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=tf.zeros(shape=[BATCH_SIZE], dtype=tf.float32),\n",
    "            predictions=tf.cast((disc_fake > 0.5),tf.float32),\n",
    "            name='acc_op')\n",
    "        # accuracy 계산, discriminator가 fake를 0.5 이하로 판정한 정확도\n",
    "\n",
    "                \n",
    "        saver = tf.train.Saver()\n",
    "        # checkpoint 저장할 Saver객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "        # Session객체 생성, 컨텍스트 매니저로 자원 관리\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # global weight 초기화\n",
    "            \n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            # local weight 초기화\n",
    "\n",
    "            for step in range(TRAINING_STEPS):\n",
    "                \n",
    "                step += 1\n",
    "                \n",
    "                disc_loss_now, gen_loss_now, accuracy_now, _, _ = sess.run(\n",
    "                    [disc_loss, gen_loss, accuracy, op_disc, op_gen])\n",
    "                # discrimiantor, generator 모두 feedforward, backpropagation 실행\n",
    "                                \n",
    "                if (step == TRAINING_STEPS):\n",
    "                    saver.save(sess, CKPT_DIR + '/gan.ckpt')\n",
    "                # train 종료시 학습된 weight에 대한 checkpoint 저장\n",
    "                                \n",
    "                if (step % 1000 == 0):\n",
    "                    print('steps: {}/{}, disc_loss: {:.4f}, gen loss: {:.4f}, accuracy: {:.4f}'.format(\n",
    "                        step, TRAINING_STEPS, disc_loss_now, gen_loss_now, accuracy_now[0]))\n",
    "                    # 학습과정 로깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion-MNIST 데이터 로드 및 전처리\n",
    "- Fashion-MNIST 데이터 로드\n",
    "- normalize\n",
    "- flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (tf.keras.datasets.fashion_mnist.load_data()[0][0] - 127.5) / 127.5\n",
    "# Fashion-MNIST 데이터 로드 (keras.datesets 모듈 이용)\n",
    "# Fashion-MNIST 데이터 normalize (0~1로 mapping)\n",
    "\n",
    "x_train = x_train.reshape([-1, 28, 28, 1]).astype(np.float32)\n",
    "# Fashion-MNIST 데이터 vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Plotting 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_25_image_plot(seed=None):\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        random_noise = np.random.normal(size=[25, NOISE_DIM]).astype(np.float32)\n",
    "        # random noise 생성\n",
    "        \n",
    "        random_noise_input = train_input_fn(random_noise, batch_size=25)\n",
    "        # random noise tensor 생성\n",
    "        \n",
    "        random_gen = gen_model(random_noise_input) * 127.5 + 127.5\n",
    "        # random noise를 generator에 적용, Fashion-MNIST image 차원으로 임베딩\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        gs = gridspec.GridSpec(5, 5)\n",
    "        gs.update(wspace=0.05)\n",
    "        # 플로팅 사이즈, 배열, 간격 정의\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        # weight restoring 진행할 Saver 객체 생성\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            saver.restore(sess, tf.train.latest_checkpoint(CKPT_DIR))\n",
    "            # checkpoint로부터 weight 복원\n",
    "            \n",
    "            random_image = sess.run(random_gen)\n",
    "            # random generation operation 진행\n",
    "            \n",
    "            random_image = random_image.reshape([-1, 28, 28])\n",
    "            # tensorization\n",
    "            \n",
    "            for i in range(25):\n",
    "                plt.subplot(gs[i])\n",
    "                plt.axis('off')\n",
    "                plt.imshow(random_image[i], cmap = 'gray')\n",
    "            # plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_25_image_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
