{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/vae.png\" width=\"200%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 import\n",
    "* tensorflow (신경망 구성, 변수 설정, 역전파, gradient descent etc)\n",
    "* numpy (텐서 연산)\n",
    "* matplotlib (결과 그래프 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터세트 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라메터 설정\n",
    "* hyper parameter는 사용자가 정의하는 변수들 \n",
    "* learnable parameter는 학습을 통해 업데이트되는 변수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 50000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 러너블 파라메터 설정 (learnable parameter = network parameter)\n",
    "                           \n",
    "* 784 (input) $\\rightarrow$ 512 (hidden) $\\rightarrow$ 2(mean) + 2(std) $\\rightarrow$ 2 (latent)  $\\rightarrow$ 512 (hidden) $\\rightarrow$ 784 (output)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "image_dim = 784 # MNIST images are 28x28 pixels\n",
    "hidden_dim = 512\n",
    "latent_dim = 2\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n",
    "\n",
    "# tf Graph input (28x28 = 784 image size)\n",
    "input_image = tf.placeholder(tf.float32, shape=[None, image_dim])\n",
    "\n",
    "# Variables\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(glorot_init([image_dim, hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'decoder_h1': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([hidden_dim, image_dim]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([latent_dim])),\n",
    "    'decoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([image_dim]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 부분 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/vae_encoder.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x):\n",
    "\n",
    "    # encoder hidden layer 512\n",
    "    en_hidden = tf.matmul(x, weights['encoder_h1']) + biases['encoder_b1']\n",
    "    en_hidden = tf.nn.tanh(en_hidden)\n",
    "\n",
    "    # latent layer 2\n",
    "    z_mean = tf.matmul(en_hidden, weights['z_mean']) + biases['z_mean']\n",
    "    z_std = tf.matmul(en_hidden, weights['z_std']) + biases['z_std']\n",
    "\n",
    "    # Sampler: Normal (gaussian) random distribution\n",
    "    eps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n",
    "                       name='epsilon')\n",
    "    z = z_mean + tf.exp(z_std / 2) * eps\n",
    "\n",
    "    return z_mean, z_std, z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 부분 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/vae_decoder.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the decoder (with scope to re-use these layers later)\n",
    "def decoder(z):\n",
    "\n",
    "    # decoder hidden layer 512\n",
    "    de_hidden = tf.matmul(z, weights['decoder_h1']) + biases['decoder_b1']\n",
    "    de_hidden = tf.nn.tanh(de_hidden)\n",
    "    reconstruct = tf.matmul(de_hidden, weights['decoder_out']) + biases['decoder_out']\n",
    "    reconstruct = tf.nn.sigmoid(reconstruct)\n",
    "    \n",
    "    return reconstruct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Loss\n",
    "<img src=\"./img/vae_rec_loss.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence (Regularization) Loss\n",
    "<img src=\"./img/vae_kld_loss.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE Loss\n",
    "    \n",
    "# latent computation\n",
    "mean, std, latent = encoder(input_image)\n",
    "\n",
    "# Reconstruct image from latent\n",
    "reconstruct = decoder(latent)\n",
    "    \n",
    "# Reconstruction loss (binary cross entropy)\n",
    "reconstruct_loss = input_image * tf.log(1e-10 + reconstruct) \\\n",
    "                   + (1 - input_image) * tf.log(1e-10 + 1 - reconstruct)\n",
    "reconstruct_loss = -tf.reduce_sum(reconstruct_loss, 1)\n",
    "    \n",
    "# KL Divergence (regularization)loss\n",
    "kl_div_loss = 1 + std - tf.square(mean) - tf.exp(std)\n",
    "kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n",
    "\n",
    "total_loss = tf.reduce_mean(reconstruct_loss + kl_div_loss)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    # Train\n",
    "    feed_dict = {input_image: batch_x}\n",
    "    _, l = sess.run([train_op, total_loss], feed_dict=feed_dict)\n",
    "    \n",
    "    if i % 1000 == 0 or i == 1:\n",
    "        print('Step %i, Loss: %f' % (i, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Generator takes noise as input\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, latent_dim])\n",
    "\n",
    "# Rebuild the decoder to create image from noise\n",
    "decoder = tf.matmul(noise_input, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)\n",
    "\n",
    "\n",
    "# Building a manifold of generated digits\n",
    "n = 5\n",
    "x_axis = np.linspace(-3, 3, n)\n",
    "y_axis = np.linspace(-3, 3, n)\n",
    "\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i, yi in enumerate(x_axis):\n",
    "    for j, xi in enumerate(y_axis):\n",
    "        z_mu = np.array([[xi, yi]] * batch_size)\n",
    "        recon = sess.run(decoder, feed_dict={noise_input: z_mu})\n",
    "        canvas[(n - i - 1) * 28:(n - i) * 28, j * 28:(j + 1) * 28] = recon[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "Xi, Yi = np.meshgrid(x_axis, y_axis)\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
